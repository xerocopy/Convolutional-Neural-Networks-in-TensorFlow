{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "AuW-xg_bTsaF",
   "metadata": {
    "id": "AuW-xg_bTsaF"
   },
   "source": [
    "# Week 1: Using CNN's with the Cats vs Dogs Dataset\n",
    "\n",
    "\n",
    "Welcome to the 1st assignment of the course! This week, you will be using the famous `Cats vs Dogs` dataset to train a model that can classify images of dogs from images of cats. For this, you will create your own Convolutional Neural Network in Tensorflow and leverage Keras' image preprocessing utilities.\n",
    "\n",
    "You will also create some helper functions to move the images around the filesystem so if you are not familiar with the `os` module be sure to take a look a the [docs](https://docs.python.org/3/library/os.html).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dn-6c02VmqiN",
   "metadata": {
    "id": "dn-6c02VmqiN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bLTQd84RUs1j",
   "metadata": {
    "id": "bLTQd84RUs1j"
   },
   "source": [
    "Download the dataset from its original source by running the cell below. \n",
    "\n",
    "Note that the `zip` file that contains the images is unzipped under the `/tmp` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3sd9dQWa23aj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3sd9dQWa23aj",
    "lines_to_next_cell": 2,
    "outputId": "97706b76-8af1-4e37-9052-a94ab2272fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-25 00:46:52--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
      "Resolving download.microsoft.com (download.microsoft.com)... 23.62.212.111, 2600:1402:2000:1bb::e59, 2600:1402:2000:193::e59\n",
      "Connecting to download.microsoft.com (download.microsoft.com)|23.62.212.111|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 824894548 (787M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/cats-and-dogs.zip’\n",
      "\n",
      "/tmp/cats-and-dogs. 100%[===================>] 786.68M   153MB/s    in 5.6s    \n",
      "\n",
      "2022-02-25 00:46:58 (140 MB/s) - ‘/tmp/cats-and-dogs.zip’ saved [824894548/824894548]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If the URL doesn't work, visit https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n",
    "# And right click on the 'Download Manually' link to get a new URL to the dataset\n",
    "\n",
    "# Note: This is a very large dataset and will take some time to download\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
    "    -O \"/tmp/cats-and-dogs.zip\"\n",
    "\n",
    "local_zip = '/tmp/cats-and-dogs.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e_HsUV9WVJHL",
   "metadata": {
    "id": "e_HsUV9WVJHL"
   },
   "source": [
    "Now the images are stored within the `/tmp/PetImages` directory. There is a subdirectory for each class, so one for dogs and one for cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "DM851ZmN28J3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DM851ZmN28J3",
    "outputId": "73539426-0060-49ac-cd45-f6bb31704eb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12501 images of dogs.\n",
      "There are 12501 images of cats.\n"
     ]
    }
   ],
   "source": [
    "source_path = '/tmp/PetImages'\n",
    "\n",
    "source_path_dogs = os.path.join(source_path, 'Dog')\n",
    "source_path_cats = os.path.join(source_path, 'Cat')\n",
    "\n",
    "\n",
    "# os.listdir returns a list containing all files under the given path\n",
    "print(f\"There are {len(os.listdir(source_path_dogs))} images of dogs.\")\n",
    "print(f\"There are {len(os.listdir(source_path_cats))} images of cats.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G7dI86rmRGmC",
   "metadata": {
    "id": "G7dI86rmRGmC"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "There are 12501 images of dogs.\n",
    "There are 12501 images of cats.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iFbMliudNIjW",
   "metadata": {
    "id": "iFbMliudNIjW"
   },
   "source": [
    "You will need a directory for cats-v-dogs, and subdirectories for training\n",
    "and testing. These in turn will need subdirectories for 'cats' and 'dogs'. To accomplish this, complete the `create_train_test_dirs` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "F-QkLjxpmyK2",
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-QkLjxpmyK2",
    "outputId": "2e1a0061-8fc3-4248-cde1-955bfb2fd212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/cats-v-dogs/training\n",
      "/tmp/cats-v-dogs/training/cats\n",
      "/tmp/cats-v-dogs/training/dogs\n",
      "/tmp/cats-v-dogs/testing\n",
      "/tmp/cats-v-dogs/testing/cats\n",
      "/tmp/cats-v-dogs/testing/dogs\n"
     ]
    }
   ],
   "source": [
    "# Define root directory\n",
    "root_dir = '/tmp/cats-v-dogs'\n",
    "\n",
    "# Empty directory to prevent FileExistsError is the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "# GRADED FUNCTION: create_train_test_dirs\n",
    "def create_train_test_dirs(root_path):\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # HINT:\n",
    "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
    "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
    "  \n",
    "  dirs = ['training', 'testing']\n",
    "  files = ['cats','dogs']\n",
    "\n",
    "  for train_test_dirs in dirs:   \n",
    "    print(os.path.join(root_path, train_test_dirs))\n",
    "    for cats_and_dogs in files:\n",
    "      path = os.path.join(root_path, train_test_dirs, cats_and_dogs)\n",
    "      os.makedirs(path, exist_ok = True)  \n",
    "      print(os.path.join(root_path, train_test_dirs, cats_and_dogs))\n",
    "\n",
    "\n",
    "  pass\n",
    "\n",
    "  ### END CODE HERE\n",
    "\n",
    "  \n",
    "try:\n",
    "  #create_train_test_dirs(root_path=root_dir)\n",
    "  create_train_test_dirs(root_dir)\n",
    "except FileExistsError:\n",
    "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dhtL344OK00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dhtL344OK00",
    "outputId": "439842bc-85b4-4361-8f2d-b23d33313b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/cats-v-dogs/testing\n",
      "/tmp/cats-v-dogs/training\n",
      "/tmp/cats-v-dogs/testing/dogs\n",
      "/tmp/cats-v-dogs/testing/cats\n",
      "/tmp/cats-v-dogs/training/dogs\n",
      "/tmp/cats-v-dogs/training/cats\n"
     ]
    }
   ],
   "source": [
    "# Test your create_train_test_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D7A0RK3IQsvg",
   "metadata": {
    "id": "D7A0RK3IQsvg"
   },
   "source": [
    "**Expected Output (directory order might vary):**\n",
    "\n",
    "``` txt\n",
    "/tmp/cats-v-dogs/training\n",
    "/tmp/cats-v-dogs/testing\n",
    "/tmp/cats-v-dogs/training/cats\n",
    "/tmp/cats-v-dogs/training/dogs\n",
    "/tmp/cats-v-dogs/testing/cats\n",
    "/tmp/cats-v-dogs/testing/dogs\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R93T7HdE5txZ",
   "metadata": {
    "id": "R93T7HdE5txZ"
   },
   "source": [
    "Code the `split_data` function which takes in the following arguments:\n",
    "- SOURCE: directory containing the files\n",
    "\n",
    "- TRAINING: directory that a portion of the files will be copied to (will be used for training)\n",
    "- TESTING: directory that a portion of the files will be copied to (will be used for testing)\n",
    "- SPLIT SIZE: to determine the portion\n",
    "\n",
    "The files should be randomized, so that the training set is a random sample of the files, and the test set is made up of the remaining files.\n",
    "\n",
    "For example, if `SOURCE` is `PetImages/Cat`, and `SPLIT` SIZE is .9 then 90% of the images in `PetImages/Cat` will be copied to the `TRAINING` dir\n",
    "and 10% of the images will be copied to the `TESTING` dir.\n",
    "\n",
    "All images should be checked before the copy, so if they have a zero file length, they will be omitted from the copying process. If this is the case then your function should print out a message such as `\"filename is zero length, so ignoring.\"`. **You should perform this check before the split so that only non-zero images are considered when doing the actual split.**\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "- `os.listdir(DIRECTORY)` returns a list with the contents of that directory.\n",
    "\n",
    "- `os.path.getsize(PATH)` returns the size of the file\n",
    "\n",
    "- `copyfile(source, destination)` copies a file from source to destination\n",
    "\n",
    "- `random.sample(list, len(list))` shuffles a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "zvSODo0f9LaU",
   "metadata": {
    "cellView": "code",
    "id": "zvSODo0f9LaU"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: split_data\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "\n",
    "  ### START CODE HERE\n",
    "  source = os.listdir(SOURCE)\n",
    "  #print('SOURCE: ', SOURCE)\n",
    "  #print('source: ' , source)\n",
    "  all_files = []\n",
    "  for file_name in source:\n",
    "    file_path = SOURCE + file_name\n",
    "    #print('file_path: ', file_path)\n",
    "    \n",
    "    if os.path.getsize(file_path):\n",
    "      all_files.append(file_name)\n",
    "      #print('file_name: ', file_name)\n",
    "    else:\n",
    "      print('{}.jpg is zero length, so ignoring.'.format(file_name))\n",
    "\n",
    "  shuffle = random.sample(all_files, len(all_files))\n",
    "  train = shuffle[:int(SPLIT_SIZE * len(all_files))]\n",
    "  test = shuffle[int(SPLIT_SIZE * len(all_files)):]\n",
    "\n",
    "\n",
    "  for train_sample in train:\n",
    "    copyfile(SOURCE + train_sample, TRAINING + train_sample)\n",
    "  for test_sample in test: \n",
    "    copyfile(SOURCE + test_sample, TESTING + test_sample)\n",
    "\n",
    "  pass\n",
    "\n",
    "  ### END CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "FlIdoUeX9S-9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlIdoUeX9S-9",
    "outputId": "28b07adf-7bbe-45c1-8086-8a8cb2e35d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666.jpg.jpg is zero length, so ignoring.\n",
      "11702.jpg.jpg is zero length, so ignoring.\n",
      "\n",
      "\n",
      "There are 11250 images of cats for training\n",
      "There are 11250 images of dogs for training\n",
      "There are 1250 images of cats for testing\n",
      "There are 1250 images of dogs for testing\n"
     ]
    }
   ],
   "source": [
    "# Test your split_data function\n",
    "\n",
    "# Define paths\n",
    "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
    "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
    "\n",
    "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
    "TESTING_DIR = \"/tmp/cats-v-dogs/testing/\"\n",
    "\n",
    "TRAINING_CATS_DIR = os.path.join(TRAINING_DIR, \"cats/\")\n",
    "TESTING_CATS_DIR = os.path.join(TESTING_DIR, \"cats/\")\n",
    "\n",
    "TRAINING_DOGS_DIR = os.path.join(TRAINING_DIR, \"dogs/\")\n",
    "TESTING_DOGS_DIR = os.path.join(TESTING_DIR, \"dogs/\")\n",
    "\n",
    "# Empty directories in case you run this cell multiple times\n",
    "if len(os.listdir(TRAINING_CATS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_CATS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_DOGS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_DOGS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TESTING_CATS_DIR)) > 0:\n",
    "  for file in os.scandir(TESTING_CATS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TESTING_DOGS_DIR)) > 0:\n",
    "  for file in os.scandir(TESTING_DOGS_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# Define proportion of images used for training\n",
    "split_size = .9\n",
    "\n",
    "# Run the function\n",
    "# NOTE: Messages about zero length images should be printed out\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)\n",
    "\n",
    "# Check that the number of images matches the expected output\n",
    "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_CATS_DIR))} images of cats for training\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_DOGS_DIR))} images of dogs for training\")\n",
    "print(f\"There are {len(os.listdir(TESTING_CATS_DIR))} images of cats for testing\")\n",
    "print(f\"There are {len(os.listdir(TESTING_DOGS_DIR))} images of dogs for testing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zil4QmOD_mXF",
   "metadata": {
    "id": "Zil4QmOD_mXF"
   },
   "source": [
    "Now that you have successfully organized the data in a way that can be easily fed to Keras' `ImageDataGenerator`, it is time for you to code the generators that will yield batches of images, both for training and validation. For this, complete the `train_val_generators` function below.\n",
    "\n",
    "Something important to note is that the images in this dataset come in a variety of resolutions. Luckily, the `flow_from_directory` method allows you to standarize this by defining a tuple called `target_size` that will be used to convert each image to this target resolution. **For this exercise, use a `target_size` of (150, 150)**.\n",
    "\n",
    "**Note:** So far, you have seen the term `testing` being used a lot for referring to a subset of images within the dataset. In this exercise, all of the `testing` data is actually being used as `validation` data. This is not very important within the context of the task at hand but it is worth mentioning to avoid confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hvskJNOFVSaz",
   "metadata": {
    "id": "hvskJNOFVSaz"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "666.jpg is zero length, so ignoring.\n",
    "11702.jpg is zero length, so ignoring.\n",
    "```\n",
    "\n",
    "```\n",
    "There are 11250 images of cats for training\n",
    "There are 11250 images of dogs for training\n",
    "There are 1250 images of cats for testing\n",
    "There are 1250 images of dogs for testing\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fQrZfVgz4j2g",
   "metadata": {
    "cellView": "code",
    "id": "fQrZfVgz4j2g"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_val_generators\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "  # Pass in the appropiate arguments to the flow_from_directory method\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=20,\n",
    "                                                      class_mode='binary',\n",
    "                                                      target_size=(150, 150))\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "  # Pass in the appropiate arguments to the flow_from_directory method\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                                batch_size=20,\n",
    "                                                                class_mode='binary',\n",
    "                                                                target_size=(150, 150))\n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "qM7FxrjGiobD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qM7FxrjGiobD",
    "outputId": "1718e46d-4b57-4e45-e1aa-0cc261fefd95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22498 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test your generators\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, TESTING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tiPNmSfZjHwJ",
   "metadata": {
    "id": "tiPNmSfZjHwJ"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Found 22498 images belonging to 2 classes.\n",
    "Found 2500 images belonging to 2 classes.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TI3oEmyQCZoO",
   "metadata": {
    "id": "TI3oEmyQCZoO"
   },
   "source": [
    "One last step before training is to define the architecture of the model that will be trained.\n",
    "\n",
    "Complete the `create_model` function below which should return a Keras' `Sequential` model.\n",
    "\n",
    "Aside from defining the architecture of the model, you should also compile it so make sure to use a `loss` function that is compatible with the `class_mode` you defined in the previous exercise, which should also be compatible with the output of your network. You can tell if they aren't compatible if you get an error during training.\n",
    "\n",
    "**Note that you should use at least 3 convolution layers to achieve the desired performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ad2lybCDP6C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ad2lybCDP6C",
    "outputId": "52d8d6a3-732a-4eff-f9ca-7f99330f8a41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "labels batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "oDPK8tUB_O9e",
   "metadata": {
    "cellView": "code",
    "id": "oDPK8tUB_O9e",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# GRADED FUNCTION: create_model\n",
    "def create_model():\n",
    "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
    "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
    "\n",
    "  ### START CODE HERE\n",
    "\n",
    "  model = tf.keras.models.Sequential([ \n",
    "            tf.keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu', input_shape=(150,150,3)),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "  ])\n",
    "\n",
    "  \n",
    "  model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "  \n",
    "  model.summary()\n",
    "  ### END CODE HERE\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SMFNJZmTCZv6",
   "metadata": {
    "id": "SMFNJZmTCZv6"
   },
   "source": [
    "Now it is time to train your model!\n",
    "\n",
    "**Note:** You can ignore the `UserWarning: Possibly corrupt EXIF data.` warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5qE1G6JB4fMn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qE1G6JB4fMn",
    "outputId": "a0aa19e0-e323-4e60-ff8d-45035b34bc0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 75, 75, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 37, 37, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 37, 37, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 18, 18, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 41472)             0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               21234176  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,327,937\n",
      "Trainable params: 21,327,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 12s 114ms/step - loss: 0.9612 - accuracy: 0.5400 - val_loss: 0.6809 - val_accuracy: 0.5710\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.7051 - accuracy: 0.6055 - val_loss: 0.6076 - val_accuracy: 0.6750\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.6516 - accuracy: 0.6610 - val_loss: 0.5811 - val_accuracy: 0.6930\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.6021 - accuracy: 0.6875 - val_loss: 0.6116 - val_accuracy: 0.6680\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5891 - accuracy: 0.7020 - val_loss: 0.5324 - val_accuracy: 0.7360\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.5437 - accuracy: 0.7335 - val_loss: 0.5319 - val_accuracy: 0.7550\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5243 - accuracy: 0.7330 - val_loss: 0.5158 - val_accuracy: 0.7410\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.5037 - accuracy: 0.7570 - val_loss: 0.5056 - val_accuracy: 0.7510\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.4880 - accuracy: 0.7710 - val_loss: 0.5358 - val_accuracy: 0.7400\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.4853 - accuracy: 0.7715 - val_loss: 0.5460 - val_accuracy: 0.7360\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.4754 - accuracy: 0.7790 - val_loss: 0.4657 - val_accuracy: 0.7660\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4620 - accuracy: 0.7910 - val_loss: 0.5141 - val_accuracy: 0.7640\n",
      "Epoch 13/100\n",
      " 25/100 [======>.......................] - ETA: 5s - loss: 0.4498 - accuracy: 0.8000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 13s 131ms/step - loss: 0.4631 - accuracy: 0.7920 - val_loss: 0.4558 - val_accuracy: 0.7960\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4563 - accuracy: 0.7818 - val_loss: 0.4301 - val_accuracy: 0.8090\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.4598 - accuracy: 0.7995 - val_loss: 0.4836 - val_accuracy: 0.7810\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4597 - accuracy: 0.7950 - val_loss: 0.4827 - val_accuracy: 0.7920\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.4319 - accuracy: 0.8018 - val_loss: 0.4530 - val_accuracy: 0.7900\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4366 - accuracy: 0.7975 - val_loss: 0.4846 - val_accuracy: 0.7870\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4194 - accuracy: 0.8045 - val_loss: 0.4514 - val_accuracy: 0.7830\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4506 - accuracy: 0.8025 - val_loss: 0.5267 - val_accuracy: 0.7380\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4087 - accuracy: 0.8190 - val_loss: 0.4293 - val_accuracy: 0.8030\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4139 - accuracy: 0.8170 - val_loss: 0.4254 - val_accuracy: 0.8240\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.4008 - accuracy: 0.8280 - val_loss: 0.4339 - val_accuracy: 0.8080\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.3895 - accuracy: 0.8345 - val_loss: 0.4708 - val_accuracy: 0.7890\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3792 - accuracy: 0.8273 - val_loss: 0.3804 - val_accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3872 - accuracy: 0.8280 - val_loss: 0.4791 - val_accuracy: 0.7780\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3601 - accuracy: 0.8470 - val_loss: 0.5032 - val_accuracy: 0.7990\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3978 - accuracy: 0.8260 - val_loss: 0.4291 - val_accuracy: 0.8100\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.3781 - accuracy: 0.8345 - val_loss: 0.4467 - val_accuracy: 0.7990\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3688 - accuracy: 0.8525 - val_loss: 0.4421 - val_accuracy: 0.8150\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3489 - accuracy: 0.8520 - val_loss: 0.6143 - val_accuracy: 0.7820\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.3568 - accuracy: 0.8475 - val_loss: 0.5429 - val_accuracy: 0.8160\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3343 - accuracy: 0.8609 - val_loss: 0.4614 - val_accuracy: 0.8100\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3420 - accuracy: 0.8600 - val_loss: 0.3644 - val_accuracy: 0.8440\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3273 - accuracy: 0.8580 - val_loss: 0.3880 - val_accuracy: 0.8150\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3360 - accuracy: 0.8660 - val_loss: 0.4507 - val_accuracy: 0.8040\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3253 - accuracy: 0.8710 - val_loss: 0.4518 - val_accuracy: 0.8210\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3549 - accuracy: 0.8515 - val_loss: 0.4062 - val_accuracy: 0.8390\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3275 - accuracy: 0.8714 - val_loss: 0.4936 - val_accuracy: 0.7940\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3248 - accuracy: 0.8705 - val_loss: 0.4386 - val_accuracy: 0.7860\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3337 - accuracy: 0.8550 - val_loss: 0.4219 - val_accuracy: 0.8190\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.3266 - accuracy: 0.8585 - val_loss: 0.3819 - val_accuracy: 0.8400\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.3398 - accuracy: 0.8590 - val_loss: 0.5346 - val_accuracy: 0.8030\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3215 - accuracy: 0.8665 - val_loss: 0.3668 - val_accuracy: 0.8360\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3212 - accuracy: 0.8705 - val_loss: 0.5104 - val_accuracy: 0.7900\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3033 - accuracy: 0.8795 - val_loss: 0.4753 - val_accuracy: 0.7810\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.3050 - accuracy: 0.8744 - val_loss: 0.4345 - val_accuracy: 0.8480\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2720 - accuracy: 0.8939 - val_loss: 0.4169 - val_accuracy: 0.8490\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.2921 - accuracy: 0.8960 - val_loss: 0.4086 - val_accuracy: 0.8310\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.3021 - accuracy: 0.8795 - val_loss: 0.4694 - val_accuracy: 0.8230\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.3016 - accuracy: 0.8785 - val_loss: 0.4240 - val_accuracy: 0.8300\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2895 - accuracy: 0.8845 - val_loss: 0.5206 - val_accuracy: 0.7580\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.3011 - accuracy: 0.8869 - val_loss: 0.4627 - val_accuracy: 0.8450\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2752 - accuracy: 0.8925 - val_loss: 0.4172 - val_accuracy: 0.8290\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2957 - accuracy: 0.8915 - val_loss: 0.3890 - val_accuracy: 0.8360\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2966 - accuracy: 0.8815 - val_loss: 0.4130 - val_accuracy: 0.8380\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.2857 - accuracy: 0.8870 - val_loss: 0.6520 - val_accuracy: 0.8230\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2947 - accuracy: 0.8850 - val_loss: 0.4286 - val_accuracy: 0.8500\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.2880 - accuracy: 0.8835 - val_loss: 0.4971 - val_accuracy: 0.8310\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2827 - accuracy: 0.8760 - val_loss: 0.4087 - val_accuracy: 0.8570\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2686 - accuracy: 0.8925 - val_loss: 0.3933 - val_accuracy: 0.8470\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2687 - accuracy: 0.8924 - val_loss: 0.4149 - val_accuracy: 0.8440\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.2810 - accuracy: 0.8855 - val_loss: 0.4378 - val_accuracy: 0.8410\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2817 - accuracy: 0.8880 - val_loss: 0.3709 - val_accuracy: 0.8500\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2602 - accuracy: 0.8955 - val_loss: 0.5009 - val_accuracy: 0.8290\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2822 - accuracy: 0.8884 - val_loss: 0.5682 - val_accuracy: 0.8320\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2925 - accuracy: 0.8930 - val_loss: 0.4276 - val_accuracy: 0.8540\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2934 - accuracy: 0.8905 - val_loss: 0.4198 - val_accuracy: 0.8370\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2785 - accuracy: 0.8905 - val_loss: 0.6794 - val_accuracy: 0.8220\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2787 - accuracy: 0.9019 - val_loss: 0.3862 - val_accuracy: 0.8320\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2821 - accuracy: 0.8944 - val_loss: 0.4092 - val_accuracy: 0.8390\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2738 - accuracy: 0.8939 - val_loss: 0.4502 - val_accuracy: 0.8440\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.2714 - accuracy: 0.8985 - val_loss: 0.5024 - val_accuracy: 0.8330\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2534 - accuracy: 0.9085 - val_loss: 0.3855 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2738 - accuracy: 0.8985 - val_loss: 0.4170 - val_accuracy: 0.8380\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2684 - accuracy: 0.8995 - val_loss: 0.4672 - val_accuracy: 0.8450\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2775 - accuracy: 0.8980 - val_loss: 0.4751 - val_accuracy: 0.8580\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.2524 - accuracy: 0.9065 - val_loss: 0.4749 - val_accuracy: 0.8500\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2652 - accuracy: 0.9030 - val_loss: 0.4308 - val_accuracy: 0.8510\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2858 - accuracy: 0.8955 - val_loss: 0.4448 - val_accuracy: 0.8010\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2369 - accuracy: 0.9080 - val_loss: 0.4980 - val_accuracy: 0.7670\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2798 - accuracy: 0.8910 - val_loss: 0.4650 - val_accuracy: 0.8360\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.2784 - accuracy: 0.8815 - val_loss: 0.6207 - val_accuracy: 0.8250\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.2781 - accuracy: 0.9040 - val_loss: 0.3922 - val_accuracy: 0.8650\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2825 - accuracy: 0.9025 - val_loss: 0.3899 - val_accuracy: 0.8670\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2677 - accuracy: 0.8990 - val_loss: 0.4255 - val_accuracy: 0.8460\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.2845 - accuracy: 0.8990 - val_loss: 0.4944 - val_accuracy: 0.8330\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2620 - accuracy: 0.9025 - val_loss: 0.4996 - val_accuracy: 0.8450\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 0.2756 - accuracy: 0.9030 - val_loss: 0.6288 - val_accuracy: 0.7460\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 0.2648 - accuracy: 0.9050 - val_loss: 0.4062 - val_accuracy: 0.8510\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2606 - accuracy: 0.8995 - val_loss: 0.3804 - val_accuracy: 0.8520\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2567 - accuracy: 0.9054 - val_loss: 0.4510 - val_accuracy: 0.8720\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2659 - accuracy: 0.9049 - val_loss: 0.4838 - val_accuracy: 0.8220\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2340 - accuracy: 0.9110 - val_loss: 0.7445 - val_accuracy: 0.7870\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.2393 - accuracy: 0.9075 - val_loss: 0.4643 - val_accuracy: 0.8370\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2713 - accuracy: 0.9020 - val_loss: 0.3808 - val_accuracy: 0.8660\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2439 - accuracy: 0.9105 - val_loss: 0.4414 - val_accuracy: 0.8310\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2774 - accuracy: 0.9035 - val_loss: 0.4052 - val_accuracy: 0.8420\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.2786 - accuracy: 0.9000 - val_loss: 0.5382 - val_accuracy: 0.8540\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2414 - accuracy: 0.9110 - val_loss: 0.5415 - val_accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "# Get the untrained model\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "# Note that this may take some time.\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=100,  \n",
    "                    # Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch.\n",
    "                    validation_steps=50, \n",
    "                    # Only relevant if validation_data is provided and is a tf.data dataset. \n",
    "                    # Total number of steps (batches of samples) to draw before stopping when \n",
    "                    # performing validation at the end of every epoch. If 'validation_steps' is None, \n",
    "                    # validation will run until the validation_data dataset is exhausted. In the case\n",
    "                    # of an infinitely repeated dataset, it will run into an infinite loop. \n",
    "                    # If 'validation_steps' is specified and only part of the dataset will be consumed,\n",
    "                    # the evaluation will start from the beginning of the dataset at each epoch. \n",
    "                    # This ensures that the same validation samples are used every time.\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_generator #Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "oQObLQWlzX-v",
   "metadata": {
    "id": "oQObLQWlzX-v"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_model\n",
    "def create_model():\n",
    "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
    "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
    "\n",
    "  ### START CODE HERE\n",
    "\n",
    "  model = tf.keras.models.Sequential([ \n",
    "            tf.keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = 'relu', input_shape=(150,150,3)),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), padding = 'same', activation = 'relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), padding = 'same', activation = 'relu'),\n",
    "            tf.keras.layers.MaxPooling2D(2,2),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "            tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "  ])\n",
    "\n",
    "  \n",
    "  model.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy']) \n",
    "  \n",
    "  model.summary()\n",
    "  ### END CODE HERE\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "vIIN11gCzkHd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIIN11gCzkHd",
    "outputId": "785a0c40-a052-4e67-f0cb-7132daeffc96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_18 (Conv2D)          (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 75, 75, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 37, 37, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 37, 37, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 18, 18, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 41472)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               21234176  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,327,937\n",
      "Trainable params: 21,327,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 12s 113ms/step - loss: 0.7184 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5360\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.6840 - accuracy: 0.5655 - val_loss: 0.6573 - val_accuracy: 0.6030\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.6569 - accuracy: 0.6165 - val_loss: 0.6323 - val_accuracy: 0.6570\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.6294 - accuracy: 0.6480 - val_loss: 0.6296 - val_accuracy: 0.6540\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5956 - accuracy: 0.6785 - val_loss: 0.5988 - val_accuracy: 0.6750\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.5714 - accuracy: 0.6995 - val_loss: 0.5414 - val_accuracy: 0.7240\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5489 - accuracy: 0.7145 - val_loss: 0.5671 - val_accuracy: 0.7060\n",
      "Epoch 8/100\n",
      " 12/100 [==>...........................] - ETA: 6s - loss: 0.5530 - accuracy: 0.7208"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 11s 112ms/step - loss: 0.5162 - accuracy: 0.7405 - val_loss: 0.4998 - val_accuracy: 0.7520\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.5214 - accuracy: 0.7260 - val_loss: 0.7285 - val_accuracy: 0.6170\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 0.5072 - accuracy: 0.7415 - val_loss: 0.4902 - val_accuracy: 0.7600\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4809 - accuracy: 0.7735 - val_loss: 0.5364 - val_accuracy: 0.7360\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4471 - accuracy: 0.7925 - val_loss: 0.4850 - val_accuracy: 0.7620\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4582 - accuracy: 0.7820 - val_loss: 0.4584 - val_accuracy: 0.7840\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4621 - accuracy: 0.7780 - val_loss: 0.4593 - val_accuracy: 0.7900\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.4143 - accuracy: 0.8085 - val_loss: 0.4914 - val_accuracy: 0.7670\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4438 - accuracy: 0.7900 - val_loss: 0.4608 - val_accuracy: 0.7850\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4153 - accuracy: 0.8115 - val_loss: 0.5033 - val_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.4156 - accuracy: 0.8095 - val_loss: 0.4395 - val_accuracy: 0.7830\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3906 - accuracy: 0.8170 - val_loss: 0.4612 - val_accuracy: 0.7890\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3825 - accuracy: 0.8260 - val_loss: 0.4370 - val_accuracy: 0.7950\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.4012 - accuracy: 0.8260 - val_loss: 0.4094 - val_accuracy: 0.8140\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3901 - accuracy: 0.8288 - val_loss: 0.4601 - val_accuracy: 0.7940\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3799 - accuracy: 0.8380 - val_loss: 0.4315 - val_accuracy: 0.7950\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.3461 - accuracy: 0.8500 - val_loss: 0.4525 - val_accuracy: 0.7930\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.3484 - accuracy: 0.8475 - val_loss: 0.4282 - val_accuracy: 0.7990\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.3348 - accuracy: 0.8520 - val_loss: 0.4526 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.3175 - accuracy: 0.8640 - val_loss: 0.4249 - val_accuracy: 0.8070\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.3011 - accuracy: 0.8755 - val_loss: 0.4290 - val_accuracy: 0.8320\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.3127 - accuracy: 0.8665 - val_loss: 0.4092 - val_accuracy: 0.8080\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2979 - accuracy: 0.8765 - val_loss: 0.4989 - val_accuracy: 0.7940\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.2965 - accuracy: 0.8745 - val_loss: 0.4417 - val_accuracy: 0.8240\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.2641 - accuracy: 0.8890 - val_loss: 0.4662 - val_accuracy: 0.8150\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2742 - accuracy: 0.8800 - val_loss: 0.3889 - val_accuracy: 0.8380\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2718 - accuracy: 0.8885 - val_loss: 0.4372 - val_accuracy: 0.8220\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.2549 - accuracy: 0.8920 - val_loss: 0.4201 - val_accuracy: 0.8080\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2248 - accuracy: 0.9135 - val_loss: 0.4220 - val_accuracy: 0.8220\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.2244 - accuracy: 0.9120 - val_loss: 0.4664 - val_accuracy: 0.8300\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.2143 - accuracy: 0.9140 - val_loss: 0.4417 - val_accuracy: 0.8160\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2133 - accuracy: 0.9150 - val_loss: 0.4569 - val_accuracy: 0.8240\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1944 - accuracy: 0.9290 - val_loss: 0.4798 - val_accuracy: 0.8160\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.2073 - accuracy: 0.9285 - val_loss: 0.4726 - val_accuracy: 0.8270\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.2214 - accuracy: 0.9160 - val_loss: 0.4755 - val_accuracy: 0.8390\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1804 - accuracy: 0.9290 - val_loss: 0.5039 - val_accuracy: 0.8210\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1661 - accuracy: 0.9370 - val_loss: 0.4018 - val_accuracy: 0.8570\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1808 - accuracy: 0.9345 - val_loss: 0.4901 - val_accuracy: 0.8180\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1546 - accuracy: 0.9404 - val_loss: 0.4267 - val_accuracy: 0.8310\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.1635 - accuracy: 0.9455 - val_loss: 0.4593 - val_accuracy: 0.8220\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1270 - accuracy: 0.9545 - val_loss: 0.4610 - val_accuracy: 0.8260\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1608 - accuracy: 0.9430 - val_loss: 0.5025 - val_accuracy: 0.8320\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1467 - accuracy: 0.9485 - val_loss: 0.5315 - val_accuracy: 0.8280\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1281 - accuracy: 0.9565 - val_loss: 0.4762 - val_accuracy: 0.8320\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0991 - accuracy: 0.9670 - val_loss: 0.5851 - val_accuracy: 0.8150\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.1209 - accuracy: 0.9545 - val_loss: 0.5301 - val_accuracy: 0.8330\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1265 - accuracy: 0.9605 - val_loss: 0.5326 - val_accuracy: 0.8240\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.1123 - accuracy: 0.9680 - val_loss: 0.5606 - val_accuracy: 0.8130\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0942 - accuracy: 0.9695 - val_loss: 0.5931 - val_accuracy: 0.8210\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.0885 - accuracy: 0.9645 - val_loss: 0.5873 - val_accuracy: 0.8210\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.1056 - accuracy: 0.9625 - val_loss: 0.5236 - val_accuracy: 0.8230\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0993 - accuracy: 0.9680 - val_loss: 0.5205 - val_accuracy: 0.8490\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0838 - accuracy: 0.9705 - val_loss: 0.5706 - val_accuracy: 0.8380\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.0883 - accuracy: 0.9715 - val_loss: 0.4899 - val_accuracy: 0.8310\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0826 - accuracy: 0.9780 - val_loss: 0.6735 - val_accuracy: 0.8330\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0768 - accuracy: 0.9770 - val_loss: 0.4984 - val_accuracy: 0.8500\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0690 - accuracy: 0.9785 - val_loss: 0.5772 - val_accuracy: 0.8510\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0560 - accuracy: 0.9805 - val_loss: 0.6161 - val_accuracy: 0.8540\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0820 - accuracy: 0.9715 - val_loss: 0.6080 - val_accuracy: 0.8200\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.0704 - accuracy: 0.9750 - val_loss: 0.5890 - val_accuracy: 0.8370\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0617 - accuracy: 0.9830 - val_loss: 0.5655 - val_accuracy: 0.8330\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0683 - accuracy: 0.9810 - val_loss: 0.5826 - val_accuracy: 0.8370\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0545 - accuracy: 0.9790 - val_loss: 0.7457 - val_accuracy: 0.8180\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0530 - accuracy: 0.9800 - val_loss: 0.7620 - val_accuracy: 0.8200\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0673 - accuracy: 0.9815 - val_loss: 0.7620 - val_accuracy: 0.8410\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0489 - accuracy: 0.9860 - val_loss: 0.6417 - val_accuracy: 0.8280\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0513 - accuracy: 0.9815 - val_loss: 0.6550 - val_accuracy: 0.8440\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0442 - accuracy: 0.9845 - val_loss: 0.8123 - val_accuracy: 0.8280\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 0.0699 - accuracy: 0.9755 - val_loss: 0.6966 - val_accuracy: 0.8370\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 11s 114ms/step - loss: 0.0368 - accuracy: 0.9840 - val_loss: 0.8184 - val_accuracy: 0.8320\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.0549 - accuracy: 0.9840 - val_loss: 0.6748 - val_accuracy: 0.8310\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0537 - accuracy: 0.9780 - val_loss: 0.6312 - val_accuracy: 0.8370\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0412 - accuracy: 0.9860 - val_loss: 0.6901 - val_accuracy: 0.8490\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0380 - accuracy: 0.9900 - val_loss: 0.7428 - val_accuracy: 0.8330\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0532 - accuracy: 0.9815 - val_loss: 0.7690 - val_accuracy: 0.8390\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0353 - accuracy: 0.9910 - val_loss: 0.6723 - val_accuracy: 0.8540\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0242 - accuracy: 0.9950 - val_loss: 0.8027 - val_accuracy: 0.8340\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0386 - accuracy: 0.9885 - val_loss: 0.8154 - val_accuracy: 0.8180\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0495 - accuracy: 0.9870 - val_loss: 0.9814 - val_accuracy: 0.8130\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0509 - accuracy: 0.9835 - val_loss: 0.7155 - val_accuracy: 0.8350\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0353 - accuracy: 0.9865 - val_loss: 0.7143 - val_accuracy: 0.8210\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0327 - accuracy: 0.9870 - val_loss: 0.8290 - val_accuracy: 0.8210\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0337 - accuracy: 0.9915 - val_loss: 1.0484 - val_accuracy: 0.8260\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0323 - accuracy: 0.9875 - val_loss: 0.8807 - val_accuracy: 0.8380\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.8098 - val_accuracy: 0.8350\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0133 - accuracy: 0.9960 - val_loss: 0.9208 - val_accuracy: 0.8230\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.9223 - val_accuracy: 0.8290\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.0347 - accuracy: 0.9855 - val_loss: 1.1532 - val_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 0.0504 - accuracy: 0.9805 - val_loss: 1.0462 - val_accuracy: 0.8340\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 11s 111ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.9513 - val_accuracy: 0.8350\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0212 - accuracy: 0.9935 - val_loss: 1.0931 - val_accuracy: 0.8280\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 11s 112ms/step - loss: 0.0364 - accuracy: 0.9885 - val_loss: 1.0668 - val_accuracy: 0.8200\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 11s 113ms/step - loss: 0.0425 - accuracy: 0.9865 - val_loss: 0.9863 - val_accuracy: 0.8260\n"
     ]
    }
   ],
   "source": [
    "# Get the untrained model\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "# Note that this may take some time.\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=100,  \n",
    "                    # Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch.\n",
    "                    validation_steps=50, \n",
    "                    # Only relevant if validation_data is provided and is a tf.data dataset. \n",
    "                    # Total number of steps (batches of samples) to draw before stopping when \n",
    "                    # performing validation at the end of every epoch. If 'validation_steps' is None, \n",
    "                    # validation will run until the validation_data dataset is exhausted. In the case\n",
    "                    # of an infinitely repeated dataset, it will run into an infinite loop. \n",
    "                    # If 'validation_steps' is specified and only part of the dataset will be consumed,\n",
    "                    # the evaluation will start from the beginning of the dataset at each epoch. \n",
    "                    # This ensures that the same validation samples are used every time.\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_generator #Data on which to evaluate the loss and any model metrics at the end of each epoch. \n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VGsaDMc-GMd4",
   "metadata": {
    "id": "VGsaDMc-GMd4"
   },
   "source": [
    "Once training has finished, you can run the following cell to check the training and validation accuracy achieved at the end of each epoch.\n",
    "\n",
    "**To pass this assignment, your model should achieve a training accuracy of at least 95% and a validation accuracy of at least 80%**. If your model didn't achieve these thresholds, try training again with a different model architecture and remember to use at least 3 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "MWZrJN4-65RC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "MWZrJN4-65RC",
    "outputId": "dd7f2b73-83d6-4c0a-8385-ff0846e6ddc2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NYIaqsN2pav6",
   "metadata": {
    "id": "NYIaqsN2pav6"
   },
   "source": [
    "You will probably encounter that the model is overfitting, which means that it is doing a great job at classifying the images in the training set but struggles with new data. This is perfectly fine and you will learn how to mitigate this issue in the upcoming week.\n",
    "\n",
    "Before downloading this notebook and closing the assignment, be sure to also download the `history.pkl` file which contains the information of the training history of your model. You can download this file by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "yWcrc9nZTsHj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "yWcrc9nZTsHj",
    "outputId": "2c006d4a-8ff7-413b-f367-31cbf3073ae2"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_9cd22ca0-20dd-4795-b068-6dfa391a45b7\", \"history.pkl\", 3688)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def download_history():\n",
    "  import pickle\n",
    "  from google.colab import files\n",
    "\n",
    "  with open('history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "  files.download('history.pkl')\n",
    "\n",
    "download_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gcBcDNWTZ75Q",
   "metadata": {
    "id": "gcBcDNWTZ75Q"
   },
   "source": [
    "You will also need to submit this notebook for grading. To download it, click on the `File` tab in the upper left corner of the screen then click on `Download` -> `Download .ipynb`. You can name it anything you want as long as it is a valid `.ipynb` (jupyter notebook) file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joAaZSWWpbOI",
   "metadata": {
    "id": "joAaZSWWpbOI"
   },
   "source": [
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a convolutional neural network that classifies images of cats and dogs, along with the helper functions needed to pre-process the images!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of C2W1_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
